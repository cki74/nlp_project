# 🚀 Few-Shot 프롬프팅을 통한 경량 모델의 SQL 생성 최적화 분석

이 프로젝트는 대규모 언어 모델(LLM)의 높은 비용과 느린 추론 속도 문제를 해결하기 위해, **1.2B 수준의 작은 모델에 Few-Shot 기법을 적용하여 8B급 모델 수준의 Text-to-SQL 성능을 확보**하는 전략을 검증합니다.

---

## 📌 핵심 메시지 (Main Story)
- **성능의 재발견**: 1.2B 모델도 적절한 예시(Few-Shot)만 있다면 7~8B 모델의 Baseline 성능에 근접하거나 능가할 수 있습니다.
- **압도적 가성비**: 고가의 GPU 리소스 없이도 저사양 인프라(T4 GPU 등)에서 고성능 모델 운영이 가능합니다.
- **빠른 응답 속도**: 모델 파라미터가 작을수록 추론 시간이 단축되어 실시간 서비스에 최적화된 사용자 경험을 제공합니다.

---

## 🛠 실험 환경 및 대상
- **데이터셋**: Chinook Sample Database (디지털 미디어 스토어 데이터)
- **사용 모델**:
  - **EXAONE-4.0 (1.2B)**: 경량 모델 (핵심 실험 대상)
  - **SQLCoder (7B) / Qwen3 (8B)**: 중대형 모델 (성능 비교 대조군)
- **인프라**: Google Colab T4 GPU 환경

---

## 📊 모델 점수 산출 로직 (Scoring Logic)
모델이 생성한 SQL의 품질을 단순 텍스트 비교가 아닌 **실행 기반의 정확도(Execution Accuracy)**로 평가합니다.

1. **SQL 생성**: 자연어 질의를 기반으로 모델이 SQL 쿼리 생성.
2. **문법 검사 (Syntax Check)**: 생성된 쿼리가 SQLite 문법에 부합하는지 확인.
3. **데이터베이스 실행**: 실제 SQLite DB 엔진에 쿼리를 입력하여 실행 성공 여부 확인.
4. **결과값 비교 (Value Matching)**:
   - 정답(Golden Query) 실행 결과와 모델 생성 쿼리 실행 결과를 행(Row) 단위로 비교.
   - 단순 텍스트 일치가 아닌 **실제 추출된 데이터의 정확성**을 검증.
5. **최종 Score 산출**: `(성공한 쿼리 수 / 전체 테스트 케이스) * 100`

---

## 📈 분석 결과 및 인사이트

### 1. Baseline vs Few-Shot 성능 비교
* **Baseline (Zero-Shot)**: 1.2B 모델은 스키마 정보가 부족하여 테이블 조인이나 컬럼 매핑에서 다수의 오류 발생.
* **Few-Shot 개선**: 20개의 예시(Context)를 추가한 결과, 1.2B 모델의 정확도가 비약적으로 상승하여 **대형 모델의 Baseline 성능과 대등한 수준**을 기록.

### 2. 효율성 분석 (Efficiency)
| 항목 | 대형 모델 (7B~8B) | 경량 모델 (1.2B) + Few-Shot |
| :--- | :---: | :---: |
| **추론 속도 (Latency)** | 낮음 (생성 속도 느림) | **매우 빠름 (실시간 응답 가능)** |
| **GPU 리소스** | 고사양 GPU 필요 | **T4 등 저사양 GPU 최적화** |
| **운영 비용** | 높음 | **매우 경제적 (최대 80% 절감)** |

---

## 💡 결론
본 프로젝트를 통해 **Few-Shot 프롬프팅 기술이 모델 파라미터 크기의 차이를 적합한 도메인과 다운스트림 테스트에서는 대안이 될 수 있는 가능성**을 확인 할 수 있었습니다.  리소스가 제한된 환경에서 고성능 Text-to-SQL 서비스를 구현하고자 할 때, **경량 모델(1.2B) + Few-Shot 전략**은 성능과 경제성을 모두 잡을 수 있는 대안이 될 수 있다고 사료됩니다.

---

## 📂 실행 방법
1. `NLP_Project.ipynb` 파일을 Google Colab에서 엽니다.
2. T4 GPU 런타임을 연결합니다.
3. 노트북 내의 모델 설치 및 실행 코드 셀을 순차적으로 실행하여 성능 개선 결과를 직접 확인합니다.
